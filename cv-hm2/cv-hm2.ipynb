{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.课堂code复现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./lenna.jpg')\n",
    "cv2.imshow('lenna', img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gaussian kernel ---- 1 derivative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel Effect\n",
    "g_img = cv2.GaussianBlur(img,(7,7),5)# kernel variance\n",
    "cv2.imshow('gaussian_blur_lenna', g_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像变更模糊，因为范围更大，平均效果更明显\n",
    "g_img = cv2.GaussianBlur(img,(17,17),5)\n",
    "cv2.imshow('gaussian_blur_lenna', g_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 图像更清晰，因为方差更小，高斯图像更尖锐，中心点起的作用更大\n",
    "g_img = cv2.GaussianBlur(img,(7,7),1)\n",
    "cv2.imshow('gaussian_blur_lenna', g_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12895603]\n",
      " [0.14251846]\n",
      " [0.15133131]\n",
      " [0.1543884 ]\n",
      " [0.15133131]\n",
      " [0.14251846]\n",
      " [0.12895603]]\n"
     ]
    }
   ],
   "source": [
    "# 来看看高斯核\n",
    "kernel = cv2.getGaussianKernel(7, 5)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为啥一维，因为一维运算快\n",
    "# 理论解释\n",
    "# 用显式地代码看隐式地高斯和显示地分步高斯地效果\n",
    "g1_img = cv2.GaussianBlur(img,(7,7),5)\n",
    "g2_img = cv2.sepFilter2D(img, -1, kernel, kernel) # ori, depth, kernelX, kernelY\n",
    "cv2.imshow('g1_blur_lenna', g1_img)\n",
    "cv2.imshow('g2_blur_lenna', g2_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd derivative: laplacian （双边缘效果）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双边缘\n",
    "kernel_lap = np.array([[0,1,0],[1,-4,1],[0,1,0]],np.float32)\n",
    "lap_img = cv2.filter2D(img,-1,kernel = kernel_lap)\n",
    "cv2.imshow('lap_lenna', lap_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharp = np.array([[0, 1, 0], [1, -3, 1], [0, 1, 0]], np.float32) \n",
    "lap_img = cv2.filter2D(img, -1, kernel=kernel_sharp)\n",
    "cv2.imshow('sharp_lenna', lap_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "# 这样不对，因为，周围有4个1，中间是-3，虽然有边缘效果，但是周围得1会使得原kernel有滤波效果，使图像模糊；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决：所以取kernel_lap得相反数，再加上原图像，这样突出了中心像素，效果类似于小方差的高斯，所以可以既有边缘效果，又保留图像清晰度\n",
    "kernel_sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32) \n",
    "lap_img = cv2.filter2D(img, -1, kernel=kernel_sharp)\n",
    "cv2.imshow('sharp_lenna', lap_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "#类似锐化效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更“凶猛”的边缘效果\n",
    "# 不仅考虑x-y方向上的梯度，同时考虑了对角线方向上的梯度\n",
    "kernel_sharp = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]], np.float32) \n",
    "lap_img = cv2.filter2D(img, -1, kernel=kernel_sharp)\n",
    "cv2.imshow('sharp_lenna', lap_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边缘检测\n",
    "# x轴\n",
    "edgex = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], np.float32)\n",
    "sharp_img = cv2.filter2D(img, -1, kernel=edgex)\n",
    "cv2.imshow('edgex_lenna', sharp_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# y轴\n",
    "edgey = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "sharpy_img = cv2.filter2D(img, -1, kernel=edgey)\n",
    "cv2.imshow('edgex_lenna', sharp_img)\n",
    "cv2.imshow('edgey_lenna', sharpy_img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 角点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./board.jpg')\n",
    "img = cv2.resize(img, (640, 480))\n",
    "img_gray = np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "print(img_gray)\n",
    "\n",
    "img_harris = cv2.cornerHarris(img_gray, 2, 3, 0.05)\n",
    "cv2.imshow('img_harris ', img_harris)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "# 没法看原因：1. float类型； 2. img_harris本质上是每个pixel对于Harris函数的响应值\n",
    "# 没有看的价值\n",
    "print(img_harris)\n",
    "\n",
    "# 为了显示清楚\n",
    "# img_harris = cv2.dilate(img_harris , None)\n",
    "\n",
    "thres = 0.05 * np.max(img_harris)\n",
    "img[img_harris > thres] = [0, 0, 255]\n",
    "cv2.imshow('img_harris ', img)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lenna.jpg')\n",
    "# create sift class\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# detect SIFT\n",
    "kp = sift.detect(img,None)   # None for mask\n",
    "# compute SIFT descriptor 检测关键点和对应的描述子\n",
    "kp,des = sift.compute(img,kp)\n",
    "print(des.shape)\n",
    "img_sift= cv2.drawKeypoints(img,kp,outImage=np.array([]), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('lenna_sift.jpg', img_sift)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.median blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finish 2D convolution/filtering by your self. \n",
    "What you are supposed to do can be described as \"median blur\", which means by using a sliding window on an image, your task is not going to do a normal convolution, but to find the median value within that crop.\n",
    "\n",
    "You can assume your input has only one channel. (a.k.a a normal 2D list/vector) And you do need to consider the padding method and size. There are 2 padding ways: REPLICA & ZERO. When \"REPLICA\" are given to you, the padded pixels are the same with the border pixels. E.g is [1 2 3] is your image, the padded version will be [(...1 1) 1 2 3 (3 3...)] where how many 1 & 3 in the parenthesis depends on your padding size. When \"ZERO\", the padded version will be [(...0 0) 1 2 3 (0 0...)]\n",
    "\n",
    "Assume your input's size of the image is W x H, kernel size's m x n. You may first complete a version with O(W·H·m·n log(m·n)) to O(W·H·m·n·m·n)). \n",
    "\n",
    "Follow up 1: Can it be completed in a shorter time complexity?\n",
    "\n",
    "Follow up 2: Can it be completed in O(W·H·m·n)?\n",
    "\n",
    "Python version:\n",
    "def medianBlur(img, kernel, padding_way):\n",
    "\n",
    "    img & kernel is List of List; padding_way a string\n",
    "\n",
    "Please finish your code under this blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medianBlur(img,kernel,padding_way):\n",
    "    s = list(kernel)\n",
    "    m,n = s[0],s[1]\n",
    "    img_new = img\n",
    "    if padding_way ==\"REPLICA\":\n",
    "        img = np.array(img)\n",
    "        img = np.pad(img,((math.ceil((m-1)/2),math.floor((n-1)/2)),(math.ceil((m-1)/2),math.floor((n-1)/2))),'edge')\n",
    "    if padding_way ==\"ZERO\":\n",
    "        img = np.array(img)\n",
    "        img = np.pad(img,((math.ceil((m-1)/2),math.floor((n-1)/2)),(math.ceil((m-1)/2),math.floor((n-1)/2))),'constant')\n",
    "        \n",
    "    W = img.shape[0]\n",
    "    H = img.shape[1]\n",
    "    i = 0\n",
    "    while i <= W-m:\n",
    "        j = 0\n",
    "        while j<=H-n:\n",
    "            img_new[i][j] = np.median(img[i:i+m-1,j:j+n-1]).astype(img.dtype)\n",
    "            j+=1\n",
    "        i+=1\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./lenna.jpg', 0)\n",
    "cv2.imshow('img', img)\n",
    "#img = img[100:200, 100:200]\n",
    "img_blur_1 = medianBlur(img, (10,10), 'ZERO')\n",
    "img_blur_2 = medianBlur(img, (10,10), 'REPLICA')\n",
    "cv2.imshow('img_blur_1', img_blur_1)\n",
    "cv2.imshow('img_blur_2', img_blur_2)\n",
    "key = cv2.waitKey()\n",
    "if key == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Reading + RANSAC algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We haven't told RANSAC algorithm this week. So please try to do the reading.And now, we can describe it here:\n",
    "\n",
    "We have 2 sets of points, say, Points A and Points B. We use A.1 to denote the first point in A, B.2 the 2nd point in B and so forth. Ideally, A.1 is corresponding to B.1, ... A.m corresponding B.m. However, it's obvious that the matching cannot be so perfect and the matching in our real world is like: A.1-B.13, A.2-B.24, A.3-x (has no matching), x-B.5, A.4-B.24(This is a wrong matching) ...\n",
    "\n",
    "The target of RANSAC is to find out the true matching within this messy.\n",
    "\n",
    "Algorithm for this procedure can be described like this:\n",
    "1. Choose 4 pair of points randomly in our matching points. Those four called \"inlier\" (中文： 内点) while  others \"outlier\" (中文： 外点)\n",
    "2. Get the homography of the inliers\n",
    "3. Use this computed homography to test all the other outliers. And seperated them by using a threshold into two parts:\n",
    "\n",
    " a. new inliers which is satisfied our computed homography\n",
    " \n",
    " b. new outliers which is not satisfied by our computed homography.\n",
    "\n",
    "\n",
    "4. Get our all inliers (new inliers + old inliers) and goto step 2\n",
    "5. As long as there's no changes or we have already repeated step 2-4 k, a number actually can be computed, times, we jump out of the recursion. The final homography matrix will be the one that we want.\n",
    "\n",
    "[WARNING!!! RANSAC is a general method. Here we add our matching background to that.]\n",
    "\n",
    "##### Your task: please complete pseudo code (it would be great if you hand in real code!) of this procedure.\n",
    "Python:\n",
    "\n",
    "def ransacMatching(A, B):\n",
    "\n",
    "A & B: List of List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_homo(cor_p):  #计算一个平面到另外一个平面的投影映射矩阵\n",
    "    #Get the homography of the inliers\n",
    "    alist = []# 存储系数矩阵\n",
    "    for corr in cor_p:\n",
    "        p1 = np.mat([corr.item(0), corr.item(1), 1])\n",
    "        p2 = np.mat([corr.item(2), corr.item(3), 1])\n",
    "        a1 = [-p2.item(2) * p1.item(0), -p2.item(2) * p1.item(1), -p2.item(2) * p1.item(2), 0, 0, 0,p2.item(0) * p1.item(0), p2.item(0) * p1.item(1), p2.item(0) * p1.item(2)]\n",
    "        a2 = [0, 0, 0, -p2.item(2) * p1.item(0), -p2.item(2) * p1.item(1), -p2.item(2) * p1.item(2),p2.item(1) * p1.item(0), p2.item(1) * p1.item(1), p2.item(1) * p1.item(2)]\n",
    "        alist.append(a1)\n",
    "        alist.append(a2)\n",
    "    matrix_a = np.mat(alist) # 变成矩阵形式 matrix_a 是系数矩阵\n",
    "    u, s, v = np.linalg.svd(matrix_a) #奇异值分解\n",
    "    h = np.reshape(v[8], (3, 3)) #选取最小的右奇异值，将其变成3*3矩阵\n",
    "    h = (1 / h.item(8)) * h # 使单应性矩阵最后一个值为1\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometricDistance(corresponse, h):\n",
    "    p1 = np.transpose(np.mat([corresponse[0].item(0), corresponse[0].item(1), 1]))\n",
    "    p2 = np.transpose(np.mat([corresponse[0].item(2), corresponse[0].item(3), 1]))\n",
    "\n",
    "    diff = p2 - np.dot(h, p1) # p1 in queryIdx * h 映射回trainIdx 和 p2 in trainIdx 求距离\n",
    "    return np.linalg.norm(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instruction of cv2.BFMatcher \n",
    "https://www.jianshu.com/p/ed57ee1056ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransacMatching(A,B):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2, True)\n",
    "    matches = matcher.match(A[1], B[1])\n",
    "    cor_p = [] #存放匹配点\n",
    "    for match in matches:\n",
    "        (x1, y1) = A[0][match.queryIdx].pt  #(x1,y1) is coordinate of match point in A----queryIdx\n",
    "        (x2, y2) = B[0][match.trainIdx].pt  #(x2,y2) is coordinate of match point in B----trainIdx\n",
    "        cor_p.append([x1, y1, x2, y2])\n",
    "    cor_p = np.mat(cor_p)\n",
    "    maxInliers = []\n",
    "    finalH = None\n",
    "    inliers = []\n",
    "    \n",
    "    #randomly choose 4 matches\n",
    "    for j in range(4): \n",
    "        tem = random.randrange(0,len(cor_p))\n",
    "        inliers.append(cor_p[tem])\n",
    "        \n",
    "    outliers = cor_p\n",
    "    \n",
    "    for i in range(1000):   #迭代求取最大的inliers和 单应性矩阵\n",
    "        h = calculate_homo(inliers)\n",
    "        \n",
    "        for k in range(len(outliers)):  #计算每个局外点与单应性矩阵的距离，对局外点进行分类\n",
    "            \n",
    "            d = geometricDistance(outliers[k], h)\n",
    "            if d < 5:\n",
    "                inliers.append(outliers[k])\n",
    "                \n",
    "        if len(inliers) > len(maxInliers):\n",
    "            maxInliers = inliers\n",
    "            finalH = h\n",
    "            \n",
    "        if len(inliers) == len(maxInliers):  # 当局内点数量不再增加，跳出循环\n",
    "            break\n",
    "            \n",
    "    return finalH, maxInliers, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMatches(img1, img2, kp1, kp2, matches, inliers):\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    out = np.zeros((max(rows1, rows2), cols1 + cols2, 3), dtype='uint8')\n",
    "    out[0:rows1, 0:cols1, :] = img1\n",
    "    out[0:rows2, cols1:, :] = img2\n",
    "\n",
    "    for i in matches:\n",
    "        img1_idx = i.queryIdx\n",
    "        img2_idx = i.trainIdx\n",
    "        (x1, y1) = kp1[img1_idx].pt\n",
    "        (x2, y2) = kp2[img2_idx].pt\n",
    "\n",
    "        if inliers is not None:\n",
    "            cv2.line(out, (int(x1), int(y1)), (int(x2)+cols1, int(y2)), (0, 255, 0), 1)\n",
    "\n",
    "        if inliers is None:\n",
    "            cv2.line(out, (int(x1), int(y1)), (int(x2)+cols1, int(y2)), (255, 0, 0), 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # read an image\n",
    "    img1 = cv2.imread('img1.png')\n",
    "    img2 = cv2.imread('img2.png')\n",
    "\n",
    "    # find key point and descriptors of img1\n",
    "    sift1 = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1 = sift1.detect(img1, None)\n",
    "    kp1, des1 = sift1.compute(img1, kp1)\n",
    "\n",
    "    # find key point and descriptors of img2\n",
    "    sift2 = cv2.xfeatures2d.SIFT_create()\n",
    "    kp2 = sift2.detect(img2, None)\n",
    "    kp2, des2 = sift2.compute(img2, kp2)\n",
    "\n",
    "    A = []\n",
    "    B = []\n",
    "    A.append(kp1)\n",
    "    A.append(des1)\n",
    "    B.append(kp2)\n",
    "    B.append(des2) #A[0] and B[0] keypoint/A[1] and B[1] descriptors each descriptor has 128 dimensions\n",
    "    finalH, MaxInliers, matches = ransacMatching(A,B)\n",
    "    imgout = drawMatches(img1, img2, kp1, kp2, matches, MaxInliers)\n",
    "    print('final homography', finalH)\n",
    "    print('final inliers count', len(MaxInliers))\n",
    "    cv2.imwrite('matchimg.png', imgout)\n",
    "    cv2.imshow('imgout', imgout)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final homography [[ 5.63590619e-02 -9.83063396e-01  2.07603806e+02]\n",
      " [ 5.09760701e-02 -8.33847761e-01  1.75033563e+02]\n",
      " [ 3.54802300e-04 -4.84296684e-03  1.00000000e+00]]\n",
      "final inliers count 4\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
